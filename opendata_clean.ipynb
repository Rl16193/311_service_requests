{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec1d8a57",
   "metadata": {},
   "source": [
    "Operations in Excel: Copy and insert the creation date column and rename it creation time.\n" 
    "Change the data format for the Creation Date column to Short Date and the Creation Time column to time.\n",
    "Add a sub-section header after the section column (for environment division requests)\n",
    "\n",
    "Take individual 311 requests files for each year, concat them to obtain total requests for the study period (2014 - Present)\n",
    "\n",
    "Employ Data Cleaning Techniques to maintain consistency across wards, service request types and divisions (map new category names to the old ones, group low occuring requests as others)\n",
    "\n",
    "Separate the 311 requests based on City Divisions\n",
    "\n",
    "Upload requests for each division to PostGreSQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f1acb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e513f6a",
   "metadata": {},
   "source": [
    "Gathering the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "32890311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_3152\\1094642037.py:10: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sr_2021 = pd.read_csv('OpenData/311servicerequests/SR2021.csv')\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_3152\\1094642037.py:16: DtypeWarning: Columns (46,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  weather = pd.read_csv('OpenData/Data/weatherstats_toronto_daily.csv')\n"
     ]
    }
   ],
   "source": [
    "# Import the datasets\n",
    "\n",
    "sr_2014 = pd.read_csv('OpenData/311servicerequests/SR2014.csv')\n",
    "sr_2015 = pd.read_csv('OpenData/311servicerequests/SR2015.csv')\n",
    "sr_2016 = pd.read_csv('OpenData/311servicerequests/SR2016.csv')\n",
    "sr_2017 = pd.read_csv('OpenData/311servicerequests/SR2017.csv')\n",
    "sr_2018 = pd.read_csv('OpenData/311servicerequests/SR2018.csv')\n",
    "sr_2019 = pd.read_csv('OpenData/311servicerequests/SR2019.csv')\n",
    "sr_2020 = pd.read_csv('OpenData/311servicerequests/SR2020.csv')\n",
    "sr_2021 = pd.read_csv('OpenData/311servicerequests/SR2021.csv')\n",
    "sr_2022 = pd.read_csv('OpenData/311servicerequests/SR2022.csv')\n",
    "sr_2023 = pd.read_csv('OpenData/311servicerequests/SR2023.csv')\n",
    "sr_2024 = pd.read_csv('OpenData/311servicerequests/SR2024.csv')\n",
    "sr_2025 = pd.read_csv('OpenData/311servicerequests/SR2025.csv', encoding = \"iso-8859-1\")\n",
    "\n",
    "weather = pd.read_csv('OpenData/Data/weatherstats_toronto_daily.csv')\n",
    "wards = pd.read_csv('OpenData/Data/2023-WardProfiles-GeographicAreas.csv')\n",
    "collisions = pd.read_csv('OpenData/Data/Traffic_Collisions_Open_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b2f51088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_date</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>status</th>\n",
       "      <th>postal_code_f3</th>\n",
       "      <th>intersection_street_1</th>\n",
       "      <th>intersection_street_2</th>\n",
       "      <th>ward</th>\n",
       "      <th>service_request_type</th>\n",
       "      <th>division</th>\n",
       "      <th>section</th>\n",
       "      <th>sub_section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>12:20:47 AM</td>\n",
       "      <td>Closed</td>\n",
       "      <td>M5R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trinity-Spadina (20)</td>\n",
       "      <td>Graffiti</td>\n",
       "      <td>Municipal Licensing &amp; Standards</td>\n",
       "      <td>District Enforcement</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>12:28:26 AM</td>\n",
       "      <td>Closed</td>\n",
       "      <td>M4E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beaches-East York (32)</td>\n",
       "      <td>STRAY AT LARGE</td>\n",
       "      <td>Municipal Licensing &amp; Standards</td>\n",
       "      <td>Toronto Animal Services</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>12:39:31 AM</td>\n",
       "      <td>Closed</td>\n",
       "      <td>M6B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Paul's (21)</td>\n",
       "      <td>Storm Clean Up</td>\n",
       "      <td>Urban Forestry</td>\n",
       "      <td>Forestry Operations</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>12:42:41 AM</td>\n",
       "      <td>Closed</td>\n",
       "      <td>M6B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Paul's (21)</td>\n",
       "      <td>Storm Clean Up</td>\n",
       "      <td>Urban Forestry</td>\n",
       "      <td>Forestry Operations</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1:00:31 AM</td>\n",
       "      <td>Closed</td>\n",
       "      <td>M5T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trinity-Spadina (20)</td>\n",
       "      <td>Graffiti</td>\n",
       "      <td>Municipal Licensing &amp; Standards</td>\n",
       "      <td>District Enforcement</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  creation_date creation_time  status postal_code_f3 intersection_street_1  \\\n",
       "0    2014-01-01   12:20:47 AM  Closed            M5R                   NaN   \n",
       "1    2014-01-01   12:28:26 AM  Closed            M4E                   NaN   \n",
       "2    2014-01-01   12:39:31 AM  Closed            M6B                   NaN   \n",
       "3    2014-01-01   12:42:41 AM  Closed            M6B                   NaN   \n",
       "4    2014-01-01    1:00:31 AM  Closed            M5T                   NaN   \n",
       "\n",
       "  intersection_street_2                    ward service_request_type  \\\n",
       "0                   NaN    Trinity-Spadina (20)             Graffiti   \n",
       "1                   NaN  Beaches-East York (32)       STRAY AT LARGE   \n",
       "2                   NaN         St. Paul's (21)       Storm Clean Up   \n",
       "3                   NaN         St. Paul's (21)       Storm Clean Up   \n",
       "4                   NaN    Trinity-Spadina (20)             Graffiti   \n",
       "\n",
       "                          division                  section sub_section  \n",
       "0  Municipal Licensing & Standards     District Enforcement         NaN  \n",
       "1  Municipal Licensing & Standards  Toronto Animal Services         NaN  \n",
       "2                   Urban Forestry      Forestry Operations         NaN  \n",
       "3                   Urban Forestry      Forestry Operations         NaN  \n",
       "4  Municipal Licensing & Standards     District Enforcement         NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all the datasets into one dataframe\n",
    "\n",
    "sr_311 = pd.concat([sr_2014, sr_2015, sr_2016, sr_2017, sr_2018, sr_2019, sr_2020, sr_2021, sr_2022, sr_2023, sr_2024, sr_2025], ignore_index=True)\n",
    "sr_311.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33c67d3",
   "metadata": {},
   "source": [
    "Remove Unknown and NSA values from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "408ae311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop accidents with no specified area \n",
    "collisions_cleaned = collisions[collisions['NEIGHBOURHOOD_158']!='NSA'].copy()\n",
    "collisions_cleaned.fillna(0, inplace = True)\n",
    "\n",
    "# Due to limitations of the geocoding service, we will store the rows without ward names separately.\n",
    "address_to_coord = sr_311[(sr_311['ward'].isna()) | (sr_311['ward'].str.strip().isin(['Unknown']))]\n",
    "\n",
    "# Drop these rows from the main dataframe\n",
    "sr_311 = sr_311[(~sr_311.index.isin(address_to_coord.index))]\n",
    "sr_311 = sr_311[(~sr_311['ward'].str.strip().isin(['Unknown']))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4fdf4b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_3152\\2982699409.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  collisions_cleaned[col] = collisions_cleaned[col].replace(mapping).infer_objects(copy=False)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_3152\\2982699409.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  collisions_cleaned[col] = collisions_cleaned[col].replace(mapping).infer_objects(copy=False)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_3152\\2982699409.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  collisions_cleaned[col] = collisions_cleaned[col].replace(mapping).infer_objects(copy=False)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_3152\\2982699409.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  collisions_cleaned[col] = collisions_cleaned[col].replace(mapping).infer_objects(copy=False)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_3152\\2982699409.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  collisions_cleaned[col] = collisions_cleaned[col].replace(mapping).infer_objects(copy=False)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_3152\\2982699409.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  collisions_cleaned[col] = collisions_cleaned[col].replace(mapping).infer_objects(copy=False)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_3152\\2982699409.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  collisions_cleaned[col] = collisions_cleaned[col].replace(mapping).infer_objects(copy=False)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_3152\\2982699409.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  collisions_cleaned[col] = collisions_cleaned[col].replace(mapping).infer_objects(copy=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OBJECTID               int64\n",
       "EVENT_UNIQUE_ID       object\n",
       "OCC_DATE              object\n",
       "OCC_MONTH             object\n",
       "OCC_DOW               object\n",
       "OCC_YEAR               int64\n",
       "OCC_HOUR               int64\n",
       "DIVISION              object\n",
       "FATALITIES             int64\n",
       "INJURY_COLLISIONS      int64\n",
       "FTR_COLLISIONS         int64\n",
       "PD_COLLISIONS          int64\n",
       "HOOD_158              object\n",
       "NEIGHBOURHOOD_158     object\n",
       "LONG_WGS84           float64\n",
       "LAT_WGS84            float64\n",
       "AUTOMOBILE             int64\n",
       "MOTORCYCLE             int64\n",
       "PASSENGER              int64\n",
       "BICYCLE                int64\n",
       "PEDESTRIAN             int64\n",
       "x                    float64\n",
       "y                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map yes, no to integer values\n",
    "mapping = {'YES': 1, 'NO': 0, 'N/R':0}\n",
    "\n",
    "columns_to_clean = ['INJURY_COLLISIONS', 'FTR_COLLISIONS', 'PD_COLLISIONS','AUTOMOBILE', 'MOTORCYCLE','PASSENGER','BICYCLE','PEDESTRIAN']\n",
    "\n",
    "for col in columns_to_clean:\n",
    "    collisions_cleaned[col] = collisions_cleaned[col].replace(mapping).infer_objects(copy=False)\n",
    "    collisions_cleaned[col] = collisions_cleaned[col].astype(int)\n",
    "collisions_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c3edd2",
   "metadata": {},
   "source": [
    "Null Value Check for service requests data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "860f1a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "creation_date                  0\n",
       "creation_time                  0\n",
       "status                         0\n",
       "postal_code_f3                 0\n",
       "intersection_street_1    4301464\n",
       "intersection_street_2    4304048\n",
       "ward                           0\n",
       "service_request_type           0\n",
       "division                       0\n",
       "section                        0\n",
       "sub_section              4810418\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_311.isna().sum() # Check for missing values in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7ffe88",
   "metadata": {},
   "source": [
    "Function to remove outdated ward names, map new names (wards with changed boundaries are mapped based on approximation of First 3 Postal Code Numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5449d8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ward names in the 311 requests datasets: ['Trinity-Spadina (20)' 'Beaches-East York (32)' \"St. Paul's (21)\"\n",
      " 'York South-Weston (11)' 'York South-Weston (12)' 'Toronto-Danforth (30)'\n",
      " 'Don Valley West (25)' 'Beaches-East York (31)' 'Trinity-Spadina (19)'\n",
      " 'Don Valley East (33)' 'Eglinton-Lawrence (16)' 'Etobicoke North (02)'\n",
      " 'Scarborough-Rouge River (41)' 'Parkdale-High Park (13)'\n",
      " 'Scarborough Southwest (36)' 'Scarborough East (44)'\n",
      " 'Toronto-Danforth (29)' 'Willowdale (23)' 'Scarborough East (43)'\n",
      " 'York West (07)' 'York West (08)' 'York Centre (10)'\n",
      " 'Scarborough Southwest (35)' 'Willowdale (24)' 'Eglinton-Lawrence (15)'\n",
      " 'Scarborough-Rouge River (42)' 'Scarborough Centre (38)'\n",
      " 'Scarborough-Agincourt (40)' 'Toronto Centre-Rosedale (27)'\n",
      " 'Etobicoke Centre (04)' 'Etobicoke-Lakeshore (05)' \"St. Paul's (22)\"\n",
      " 'Etobicoke-Lakeshore (06)' 'Scarborough Centre (37)' 'Davenport (17)'\n",
      " 'Toronto Centre-Rosedale (28)' 'Etobicoke Centre (03)'\n",
      " 'Parkdale-High Park (14)' 'Davenport (18)' 'Don Valley West (26)'\n",
      " 'Don Valley East (34)' 'York Centre (09)' 'Etobicoke North (01)'\n",
      " 'Scarborough-Agincourt (39)' 'Scarborough Southwest (20)'\n",
      " 'Willowdale (18)' 'Etobicoke-Lakeshore (03)' 'Scarborough Centre (21)'\n",
      " 'Beaches-East York (19)' 'Toronto-Danforth (14)' 'York Centre (06)'\n",
      " 'Don Valley East (16)' 'Spadina-Fort York (10)'\n",
      " 'University-Rosedale (11)' 'Don Valley North (17)'\n",
      " \"Toronto-St. Paul's (12)\" 'Davenport (09)' 'Toronto Centre (13)'\n",
      " 'Humber River-Black Creek (07)' 'York South-Weston (05)'\n",
      " 'Eglinton-Lawrence (08)' 'Scarborough-Guildwood (24)'\n",
      " 'Parkdale-High Park (04)' 'Scarborough-Rouge Park (25)'\n",
      " 'Etobicoke Centre (02)' 'Don Valley West (15)' 'Scarborough North (23)'\n",
      " 'Scarborough-Agincourt (22)']\n"
     ]
    }
   ],
   "source": [
    "print('Ward names in the 311 requests datasets:', (sr_311['ward'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44de6fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ward names in the 311 requests datasets: {'Scarborough Southwest', 'University-Rosedale', 'Trinity-Spadina', 'Davenport', \"St. Paul's\", 'Scarborough Centre', 'Scarborough North', 'Scarborough-Guildwood', 'Toronto Centre', 'Humber River-Black Creek', 'Beaches-East York', \"Toronto-St. Paul's\", 'Eglinton-Lawrence', 'Don Valley West', 'Etobicoke-Lakeshore', 'Don Valley North', 'Toronto-Danforth', 'Etobicoke Centre', 'Spadina-Fort York', 'York South-Weston', 'York Centre', 'Parkdale-High Park', 'Don Valley East', 'Scarborough-Rouge Park', 'Scarborough East', 'York West', 'Toronto Centre-Rosedale', 'Scarborough-Rouge River', 'Etobicoke North', 'Scarborough-Agincourt', 'Willowdale'}\n"
     ]
    }
   ],
   "source": [
    "#Spilt Ward Names at brackets\n",
    "sr_311['ward'] = sr_311['ward'].str.split('(').str[0].str.strip()\n",
    "old_wards = set(sr_311['ward'].unique())\n",
    "print('Ward names in the 311 requests datasets:', old_wards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6035fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Present Ward Names\n",
    "new_wards = set(sr_311[sr_311['creation_date']>'2023-01-01']['ward'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5ba4a3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toronto Centre-Rosedale',\n",
       " 'York West',\n",
       " 'Scarborough-Rouge River',\n",
       " 'Trinity-Spadina',\n",
       " \"St. Paul's\",\n",
       " 'Scarborough East']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After the 2018 restructring the electoral wards reduced from 47 to 25. The ward names no longer in use but still in the dataset are:\n",
    "outdated = list(old_wards-new_wards)\n",
    "outdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a056e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsa_to_ward = {\n",
    "        # Downtown & West\n",
    "        'M6G': 'Spadina-Fort York',\n",
    "        'M6J': 'Spadina-Fort York',\n",
    "        'M5T': 'Spadina-Fort York',\n",
    "        'M5J': 'Spadina-Fort York',\n",
    "        'M5H': 'Spadina-Fort York',\n",
    "        'M5V': 'Spadina-Fort York',\n",
    "\n",
    "        # University–Rosedale\n",
    "        'M5A': 'University-Rosedale',\n",
    "        'M5R': 'University-Rosedale',\n",
    "        'M5B': 'University-Rosedale',\n",
    "        'M5S': 'University-Rosedale',\n",
    "        'M5C': 'University-Rosedale',\n",
    "        'M5E': 'University-Rosedale',\n",
    "        'M5G': 'University-Rosedale',\n",
    "        'M5X': 'University-Rosedale',\n",
    "        'M5L': 'University-Rosedale',\n",
    "        'M5K': 'University-Rosedale',\n",
    "        'M5N': 'University-Rosedale',\n",
    "\n",
    "        # Toronto–St. Paul's\n",
    "        'M4W': \"Toronto-St. Paul's\",\n",
    "        'M4Y': \"Toronto-St. Paul's\",\n",
    "        'M4X': \"Toronto-St. Paul's\",\n",
    "        'M4T': \"Toronto-St. Paul's\",\n",
    "        'M7A': \"Toronto-St. Paul's\",\n",
    "        'M4S': \"Toronto-St. Paul's\",\n",
    "        'M6C': \"Toronto-St. Paul's\",\n",
    "        'M4V': \"Toronto-St. Paul's\",\n",
    "        'M4P': \"Toronto-St. Paul's\",\n",
    "        'M4G': \"Toronto-St. Paul's\",\n",
    "        'M4R': \"Toronto-St. Paul's\",\n",
    "        'M6E': \"Toronto-St. Paul's\",\n",
    "        'M6B': \"Toronto-St. Paul's\",\n",
    "\n",
    "        # Other wards\n",
    "        'M6H': 'Davenport',\n",
    "        'M6K': 'Davenport',\n",
    "        'M9M': 'York South-Weston',\n",
    "        'M3N': 'York South-Weston',\n",
    "        'M9L': 'York South-Weston',\n",
    "        'M3L': 'York South-Weston',\n",
    "        'M3J': 'York Centre',\n",
    "        'M3H': 'York Centre',\n",
    "        'M3K': 'York Centre',\n",
    "        'M3M': 'York Centre',\n",
    "        'M1B': 'Scarborough-Agincourt',\n",
    "        'M1C': 'Scarborough Southwest',\n",
    "        'M1E': 'Scarborough Southwest',\n",
    "        'M1G': 'Scarborough Southwest',\n",
    "        'M1M': 'Scarborough Southwest',\n",
    "        'M1J': 'Scarborough Southwest',\n",
    "        'M1H': 'Scarborough Southwest',\n",
    "        'M1V': 'Scarborough-Guildwood',\n",
    "        'M1S': 'Scarborough-Guildwood',\n",
    "        'M1X': 'Scarborough North',\n",
    "        'M5P': 'Toronto Centre'\n",
    "}\n",
    "\n",
    "# Only update rows with outdated ward names\n",
    "mask = sr_311['ward'].isin(outdated)\n",
    "sr_311.loc[mask, 'ward'] = sr_311.loc[mask, 'postal_code_f3'].map(fsa_to_ward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "44bd188c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ward names in the 311 requests datasets: ['University-Rosedale' 'Beaches-East York' \"Toronto-St. Paul's\"\n",
      " 'Spadina-Fort York' 'York South-Weston' 'Toronto-Danforth'\n",
      " 'Don Valley West' 'Don Valley East' 'Toronto Centre' 'Eglinton-Lawrence'\n",
      " 'Etobicoke North' 'Scarborough-Guildwood' 'Parkdale-High Park'\n",
      " 'Scarborough Southwest' 'Scarborough-Agincourt' 'Willowdale'\n",
      " 'York Centre' 'Scarborough Centre' 'Etobicoke Centre'\n",
      " 'Etobicoke-Lakeshore' 'Davenport' nan 'Scarborough North'\n",
      " 'Don Valley North' 'Humber River-Black Creek' 'Scarborough-Rouge Park']\n"
     ]
    }
   ],
   "source": [
    "print('Ward names in the 311 requests datasets:',(sr_311['ward'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e93ecf",
   "metadata": {},
   "source": [
    "Obtain Postal Codes for wards with Null Values - As they are intersections, we can confirm our mapping function works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec5aab02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "postal_code_f3\n",
       "Intersection    61263\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_311[sr_311['ward'].isna()]['postal_code_f3'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a5b81d",
   "metadata": {},
   "source": [
    "Function to clean ward names - Remove trailing spaces and curly apostrophe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "20337380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          University-Rosedale\n",
       "1            Beaches-East York\n",
       "2           Toronto-St. Paul's\n",
       "3           Toronto-St. Paul's\n",
       "4            Spadina-Fort York\n",
       "                  ...         \n",
       "4942179         Toronto Centre\n",
       "4942180         Toronto Centre\n",
       "4942181             Willowdale\n",
       "4942182       Etobicoke Centre\n",
       "4942183     Parkdale-High Park\n",
       "Name: ward, Length: 4942153, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_311['ward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "29f80c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction to clean ward names\n",
    "def clean_ward_name(s):\n",
    "    if isinstance(s,str):\n",
    "        return s.strip().replace('’', \"'\")  # curly to straight apostrophes and reomve trailing spaces\n",
    "    return s # return unchanged if NaN\n",
    "\n",
    "wards['ward'] = wards['ward'].apply(clean_ward_name)\n",
    "sr_311['ward'] = sr_311['ward'].apply(clean_ward_name)\n",
    "collisions_cleaned['NEIGHBOURHOOD_158'] = collisions_cleaned['NEIGHBOURHOOD_158'].apply(clean_ward_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8253ec64",
   "metadata": {},
   "source": [
    "Convert date column to datetime dtype; create additional time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a72210e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the Data\n",
    "\n",
    "# 1. Fix Datatypes\n",
    "sr_311['creation_date'] = pd.to_datetime(sr_311['creation_date'])\n",
    "sr_311['creation_time'] = pd.to_datetime(sr_311['creation_time'], format='%H:%M:%S %p').dt.time\n",
    "collisions_cleaned['OCC_DATE'] = pd.to_datetime(collisions_cleaned['OCC_DATE'])\n",
    "\n",
    "# 2. Extract year, month, dayofweek from creation_date\n",
    "sr_311['year'] = sr_311['creation_date'].dt.year\n",
    "sr_311['month']=sr_311['creation_date'].dt.month_name()\n",
    "sr_311['day_of_week'] = sr_311['creation_date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e9dc5",
   "metadata": {},
   "source": [
    "Create a separate dataset where ward is Unknown or NA. Due to limited geotagging capabilities drop them from our study.\n",
    "\n",
    "Free Geotagging tools can only handle limited inputs. The dataset is saved for future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28dc3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a new address column (combining postal code and intersection street)\n",
    "\n",
    "sr_311['full_address'] = sr_311[['postal_code_f3', 'intersection_street_1', 'intersection_street_2']] \\\n",
    "    .fillna('') \\\n",
    "    .agg(', '.join, axis=1) + \" Toronto, Ontario\"\n",
    "\n",
    "# Strip extra commas\n",
    "sr_311['full_address'] = sr_311['full_address'].str.replace(r',\\s+',' ', regex=True).str.replace('Intersection','', regex=True)\n",
    "\n",
    "# Store Unknown Requests in a separate dataset\n",
    "unknown_requests = sr_311[sr_311['division']=='Unknown']\n",
    "\n",
    "# Remove Unknown Requests from the main dataset\n",
    "sr_311 = sr_311[~sr_311['division'].str.strip().isin(['Unknown'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cd7d3d",
   "metadata": {},
   "source": [
    "Further contegorize the intersections into Highway ramps, Railway/Road Intersections and Road Intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "89bd9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Change postal_code_f3 values. Adding Railway and Ramp on/off Highway categories ot the dataset.\n",
    "\n",
    "# If Intersection street names contain ramp, change postal_code_f3 to Ramp on/off Highway\n",
    "sr_311.loc[(sr_311['intersection_street_1'].str.contains('ramp', case=False, na=False)) | (sr_311['intersection_street_2'].str.contains('ramp', case=False, na=False)), 'postal_code_f3'] = 'Ramp on/off Highway'\n",
    "\n",
    "# If Intersection street names contains C N R or C P R, change postal_code_f3 to Railway\n",
    "sr_311.loc[(sr_311['intersection_street_1'].str.contains('C N R\\b', case=False, na=False)) | (sr_311['intersection_street_2'].str.contains('C N R\\b', case=False, na=False)), 'postal_code_f3'] = 'Railway'\n",
    "sr_311.loc[(sr_311['intersection_street_1'].str.contains('C P R', case=False, na=False)) | (sr_311['intersection_street_2'].str.contains('C P R', case=False, na=False)), 'postal_code_f3'] = 'Railway'\n",
    "\n",
    "#Drop intersection street and postcal code\n",
    "sr_311.drop(columns=['postal_code_f3','intersection_street_1','intersection_street_2'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770db47c",
   "metadata": {},
   "source": [
    "Clean the weather dataset, correct datatype for date column, keep only necessary columns and filter year to 2013 (1 before our study year 2014, so that it captures weather lag and rolling trends right from the start of the study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cd848a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix DataTypes in Weather Dataset\n",
    "weather['date'] = pd.to_datetime(weather['date'])\n",
    "\n",
    "# Take only the necessary rows from the climate datsets (dates after 2013)\n",
    "weather = weather[weather['date'].dt.year>2013]\n",
    "\n",
    "# Keep only necessary columns\n",
    "columns_to_keep = ['date','max_temperature','min_temperature','avg_temperature','min_windchill','avg_relative_humidity','avg_dew_point','precipitation','rain','snow',\n",
    "                   'snow_on_ground','max_wind_speed','avg_wind_speed','max_wind_gust','avg_pressure_sea','avg_visibility','daylight','avg_cloud_cover_8']\n",
    "weather = weather[columns_to_keep]\n",
    "                  \n",
    "# Add snow marker\n",
    "weather['is_snow'] = (weather['snow'] > 0)\n",
    "\n",
    "# Ensure date is sorted\n",
    "weather = weather.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Assign last_snow_date using forward fill\n",
    "weather['last_snow_date'] = weather['date'].where(weather['is_snow']).ffill()\n",
    "\n",
    "# Calculate days since last snowfall\n",
    "weather['days_since_snow'] = (weather['date'] - weather['last_snow_date']).dt.days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce260f8",
   "metadata": {},
   "source": [
    "Employ Regex case matching, remove reduntant dashes and double spaces\n",
    "\n",
    "Update old division names with new ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a6abbc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove - from the feild names, Replace double spaces and Match the case\n",
    "sr_311['service_request_type'] = sr_311['service_request_type'].str.replace('-', ' ',regex=False).str.replace(r'\\s+',' ', regex=True).str.title()\n",
    "\n",
    "# Clean the Status column\n",
    "\n",
    "# Trim trailing and leading spaces\n",
    "sr_311['status'] = sr_311['status'].str.strip()\n",
    "sr_311['section'] = sr_311['section'].str.strip()\n",
    "\n",
    "# Replace In-Progress with In Progress\n",
    "sr_311['status'] = sr_311['status'].str.replace(r'In[- ]?progress', 'In Progress',case=False, regex=True)\n",
    "\n",
    "# Fix the Parks Divisions Data (Update the Divsion, Section and Subsection names)\n",
    "sr_311.loc[sr_311['division'] == 'Urban Forestry', 'sub_section'] = sr_311.loc[sr_311['division'] == 'Urban Forestry','section']\n",
    "\n",
    "# Change Section Name\n",
    "sr_311.loc[sr_311['division'] == 'Urban Forestry', 'section'] = 'Climate & Forestry'\n",
    "sr_311.loc[sr_311['division'] == 'Parks', 'section'] = 'Climate & Forestry'\n",
    "\n",
    "# Change Division Name\n",
    "sr_311.loc[sr_311['division'] == 'Urban Forestry', 'division'] = 'Environment'\n",
    "sr_311.loc[sr_311['division'] == 'Parks', 'division'] = 'Environment'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97758cca",
   "metadata": {},
   "source": [
    "Null Value Check in the weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8d75f339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with null (NaN) values (> 0) in weather dataset:\n",
      "min_windchill: 2922\n",
      "precipitation: 18\n",
      "rain: 30\n",
      "snow: 21\n",
      "snow_on_ground: 3239\n",
      "max_wind_gust: 784\n",
      "last_snow_date: 1\n",
      "days_since_snow: 1\n"
     ]
    }
   ],
   "source": [
    "# Check for columns with null (NaN) values\n",
    "null_counts = weather.isna().sum()\n",
    "print(\"\\nColumns with null (NaN) values (> 0) in weather dataset:\")\n",
    "for col, count in null_counts.items():\n",
    "    if count > 0:\n",
    "        print(f\"{col}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d278fcab",
   "metadata": {},
   "source": [
    "Fill missing windchill with minimum temperature and replace remaining null values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5df784e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_3152\\2101543944.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  weather.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values\n",
    "\n",
    "weather['min_windchill'] = weather['min_windchill'].fillna(weather['min_temperature'])\n",
    "weather.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1a04edfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with null (NaN) values (> 0) in weather dataset:\n"
     ]
    }
   ],
   "source": [
    "# Check for columns with null (NaN) values\n",
    "null_counts = weather.isna().sum()\n",
    "print(\"\\nColumns with null (NaN) values (> 0) in weather dataset:\")\n",
    "for col, count in null_counts.items():\n",
    "    if count > 0:\n",
    "        print(f\"{col}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d819744",
   "metadata": {},
   "source": [
    "Map the correct ward number for each ward (another feature to compare wards by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1a006b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Ward Numbers based on Ward Names (Useful for establishing relationships with other datasets)\n",
    "\n",
    "ward_map = {\n",
    "    'Beaches-East York': 19,\n",
    "    'Davenport': 9,\n",
    "    'Don Valley East': 16,\n",
    "    'Don Valley North': 17,\n",
    "    'Don Valley West': 15,\n",
    "    'Eglinton-Lawrence': 8,\n",
    "    'Etobicoke Centre': 2,\n",
    "    'Etobicoke North': 1,\n",
    "    'Etobicoke-Lakeshore': 3,\n",
    "    'Humber River-Black Creek': 7,\n",
    "    'Parkdale-High Park': 4,\n",
    "    'Scarborough Centre': 21,\n",
    "    'Scarborough North': 23,\n",
    "    'Scarborough Southwest': 20,\n",
    "    'Scarborough-Agincourt': 22,\n",
    "    'Scarborough-Guildwood': 24,\n",
    "    'Scarborough-Rouge Park': 25,\n",
    "    'Spadina-Fort York': 10,\n",
    "    'Toronto Centre': 13,\n",
    "    'Toronto-Danforth': 14,\n",
    "    \"Toronto-St. Paul's\": 12,\n",
    "    'University-Rosedale': 11,\n",
    "    'Willowdale': 18,\n",
    "    'York Centre': 6,\n",
    "    'York South-Weston': 5\n",
    "}\n",
    "sr_311['ward_num'] = sr_311['ward'].map(ward_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "de65ad6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(61263)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_311['ward_num'].isna().sum() # Check for missing values in ward_num column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f3857cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Closed', 'Cancelled', 'In Progress', 'Initiated', 'Unknown',\n",
       "       'Completed', 'New'], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_311['status'].unique() # Check unique values in status column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f8361ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.Create a new dataframe for Parks related requests (as it contains an additional subsection column)\n",
    "parks_df = sr_311[sr_311['division']=='Environment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c858515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Drop the subsection column from the main dataframe\n",
    "sr_311.drop(columns = ['sub_section'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ff411b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any remaining outdated ward names\n",
    "sr_311[sr_311['ward'].isin(outdated)]['ward'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ae7832c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store transportation service requests in a separate dataframe\n",
    "transport_requests = sr_311[sr_311['division'] == 'Transportation Services']\n",
    "waste_requests = sr_311[sr_311['division']=='Solid Waste Management Services']\n",
    "municipal_requests = sr_311[sr_311['division']=='Municipal Licensing & Standards']\n",
    "water_requests = sr_311[sr_311['division']=='Toronto Water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "02d77f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_3152\\1344117282.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transport_requests['service_request_type'] = transport_requests['service_request_type'].str.replace('Plough','Plow', regex= False).str.replace('.','',regex=False).str.replace('Requested','Request',regex=False).str.replace ('Ploughing','Plowing', regex= False).str.replace('Pothole', 'Pot Hole', regex=False)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_3152\\1344117282.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transport_requests['service_request_type'] = transport_requests['service_request_type'].replace(request_map)\n"
     ]
    }
   ],
   "source": [
    "# Clean the service requests column\n",
    "request_map = {\n",
    "    # Transportation Service Requests \n",
    "    'Complaint Vendor Scg No Show': 'School Crossing Guard No Show',\n",
    "    'All Way Stop Sign Controls': 'All Way Stop Control Sign',\n",
    "    'Special Parking Consideration': 'Request For Special Parking Consideration',\n",
    "    'Complaint / Investigation Grass And Weeds Enforcement':'Long Grass And Weeds On The Boulevard',\n",
    "    'Complaint / Investigation Water Discharge':'Investigate Mud Or Water Discharge On The Street Allowance',\n",
    "    'Complaint/Investigation Abandoned Bikes':'Complaint Abandoned Bikes In Rideable Condition',\n",
    "    'Complaint/Investigation Encroachment':'Report An Encroachment On City Property',\n",
    "    'Ice And Snow Complaint':'Illegal Snow Dumping & Failure To Clear Snow Or Ice On Public Sidewalk',\n",
    "    'Complaint/Investigation Illegal Parking':'Illegal On Street Parking',\n",
    "    'Pxo Maintenance':'Pedestrian Crossover (Pxo) Maintenance',\n",
    "    'Rescu Maintenance':'Traffic Camera (Rescu) Maintenance',\n",
    "    'Traffic Sign Graffiti Complaint':'Traffic Or Street Name Sign Graffiti Complaint',\n",
    "    'Traffic Signal Graffiti Complaint':'Traffic Signal Equipment Graffiti Complaint',\n",
    "    'Missing/Damaged Signs':'Missing / Damaged Street Or Traffic Signs',\n",
    "    'Traffic Signal Maintenance':'Traffic Signal Repair',\n",
    "    'Complaint Access':'Access Complaint Road Operations',\n",
    "    'Complaint Disability':'Accessibility / Disability Complaint Transportation Services',\n",
    "    'Road Cleaning/Debris':'Clean Up Debris On Road',\n",
    "    'Illegal Dumping':'Clean Up Illegal Dumping On Roadways And Bridge Underpass',\n",
    "    'Illegal Dumping On Roadside':'Clean Up Illegal Dumping On Roadways And Bridge Underpass',\n",
    "    'Road Illegal Dumping':'Clean Up Illegal Dumping On Roadways And Bridge Underpass',\n",
    "    'Complaint Outcome Of The Service':'Outcome Of Service Complaint Road Operations',\n",
    "    'Complaint Process And Procedures':'Process And Procedures Complaint Road Operations',\n",
    "    'Complaint Regarding Contractor':'Contractor Complaint',\n",
    "    'Complaint Staff Conduct':'Staff Service Compliment Road Operations',\n",
    "    'Complaint Time Line Of The Service':'Timeliness Of Service Complaint Road Operations',\n",
    "    'Compliment Employee/Operation':'Staff Service Compliment Road Operations',\n",
    "    'Catch Basin Damaged Maintenance Requested':'Damaged Catch Basin On The Road',\n",
    "    'Catch Basin Maintenance And Repair': 'Damaged Catch Basin On The Roadside',\n",
    "    'Sidewalk Damaged / Concrete':'Damaged Concrete Sidewalk',\n",
    "    'Driveway Blocked By Windrow':'Driveway Blocked By Plowed Snowbank',\n",
    "    'Bridge Icy Needs Sand/Salt':'Icy Bridge Needs Salting',\n",
    "    'Bus Stop Icy Needs Sand/Salt':'Icy Bus Stop Needs Salting',\n",
    "    'Sidewalk Icy|| Needs Sand/Salt':'Icy Sidewalk Needs Salting',\n",
    "    'Laneway Salting / Sanding / Salt':'Laneway Needs Salting',\n",
    "    'Road Damaged':'Road Pot Hole / Road Damage',\n",
    "    'Road Pot Hole':'Road Pot Hole / Road Damage',\n",
    "    'Road Sanding / Salting Required':'Road Salting Request',\n",
    "    'Snow Removal School Zone':'School Zone Snow Clearing',\n",
    "    'Sidewalk Paraplegic Ramps':'Sidewalk Accessible Ramps & Tactile Pavers',\n",
    "    'Sidewalk Seniors Snow Clearing':'Sidewalk Snow Clearing Required',\n",
    "    'Sidewalk Snow Clearing':'Sidewalk Snow Clearing Required',\n",
    "    'Street Furniture Damaged':'Street Furniture Request',\n",
    "    'Walkway Damaged':'Walkway Damaged Or Uneven',\n",
    "    'Walkway Snow Clearing/ Salting Required':'Walkway Snow Clearing/Salting Request'\n",
    "}\n",
    "\n",
    "# Clean the service requests column\n",
    "transport_requests['service_request_type'] = transport_requests['service_request_type'].str.replace('Plough','Plow', regex= False).str.replace('.','',regex=False).str.replace('Requested','Request',regex=False).str.replace ('Ploughing','Plowing', regex= False).str.replace('Pothole', 'Pot Hole', regex=False)\n",
    "transport_requests['service_request_type'] = transport_requests['service_request_type'].replace(request_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5f8cb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Section Name\n",
    "transport_requests.loc[transport_requests['service_request_type'] == 'Pedestrian Issues/Timing/Delays', 'section'] = 'Traffic Management'\n",
    "transport_requests.loc[transport_requests['service_request_type'] == 'Signal Timing Review/Vehicle Delays', 'section'] = 'Traffic Management'\n",
    "\n",
    "# Change Service Request Type Name\n",
    "transport_requests.loc[transport_requests['service_request_type'] == 'Pedestrian Issues/Timing/Delays', 'service_request_type'] = 'Pedestrian Signal Issue'\n",
    "transport_requests.loc[transport_requests['service_request_type'] == 'Signal Timing Review/Vehicle Delays', 'service_request_type'] = 'Vehicle Traffic Signal Issue'\n",
    "\n",
    "# Define thresholds per section\n",
    "cutoffs = {\n",
    "    'TMC': 1000,\n",
    "    'Right of Way (ROW)': 1000,\n",
    "    'Traffic Ops': 1000,\n",
    "    'Road Operations': 1000\n",
    "}\n",
    "\n",
    "# Apply relabeling per section\n",
    "for section, cutoff in cutoffs.items():\n",
    "    mask = transport_requests['section'] == section\n",
    "    type_counts = transport_requests.loc[mask, 'service_request_type'].value_counts()\n",
    "    rare_types = type_counts[type_counts < cutoff].index\n",
    "\n",
    "    transport_requests.loc[mask & transport_requests['service_request_type'].isin(rare_types), 'service_request_type'] = 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f4900abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export  the cleaned dataframe to a new CSV file\n",
    "#sr_311.to_csv('C:/Users/rahul/OneDrive/Desktop/Data Analyst/Projects/OpenData/311servicerequests/sr_311_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c0a17e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ward\n",
       "Etobicoke-Lakeshore         293367\n",
       "Scarborough Southwest       292671\n",
       "Toronto-Danforth            282425\n",
       "Beaches-East York           277419\n",
       "Eglinton-Lawrence           257742\n",
       "Davenport                   254690\n",
       "Parkdale-High Park          248678\n",
       "York South-Weston           247909\n",
       "University-Rosedale         226947\n",
       "Toronto-St. Paul's          223699\n",
       "Etobicoke Centre            218808\n",
       "Don Valley West             204243\n",
       "Scarborough Centre          198456\n",
       "Spadina-Fort York           196526\n",
       "York Centre                 177754\n",
       "Willowdale                  177620\n",
       "Etobicoke North             165327\n",
       "Scarborough-Agincourt       158309\n",
       "Scarborough-Guildwood       128712\n",
       "Don Valley East             127310\n",
       "Scarborough-Rouge Park      124156\n",
       "Toronto Centre              122181\n",
       "Don Valley North             90227\n",
       "Humber River-Black Creek     87522\n",
       "Scarborough North            83565\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_311['ward'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8fec6c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "division\n",
       "Solid Waste Management Services    1843124\n",
       "Municipal Licensing & Standards    1077061\n",
       "Transportation Services            1062936\n",
       "Toronto Water                       473055\n",
       "Environment                         373424\n",
       "311                                  96587\n",
       "Parks and Recreation                   761\n",
       "City of Toronto                        578\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_311['division'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9b2136c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "service_request_type\n",
       "General Pruning                         130216\n",
       "Storm Clean Up                           85964\n",
       "Stemming                                 45125\n",
       "General Tree Maintenance                 21904\n",
       "Tree Planting                            14783\n",
       "By Law Contravention Invest              14109\n",
       "Dangerous Private Tree Investigation     12373\n",
       "Tree Emergency Clean Up                   7384\n",
       "Bees/Wasp                                 5675\n",
       "Mls Hazard Tree Invst                     4279\n",
       "Eab Exemption Request                     3648\n",
       "Residential Or Park Tree Removal          3453\n",
       "Commercial Tree Pruning                   2886\n",
       "Permit Inspection                         2574\n",
       "Private Tree Inspection                   2297\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_311[sr_311['section']=='Climate & Forestry']['service_request_type'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c135ff",
   "metadata": {},
   "source": [
    "Save the cleaned environment and transportation division 311 requests, the weather and ward datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "51095a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a PostgreSQL connection to the cleaned CSV file\n",
    "\n",
    "engine = create_engine(\"postgresql://username:password@localhost:5432/Toronto_OpenData\")\n",
    "\n",
    "# Transfer DataFrame into SQL table\n",
    "#wards.to_sql('wards',engine,if_exists='replace',index=False)\n",
    "#weather.to_sql(\"daily_weather\", engine, if_exists=\"replace\", index=False)\n",
    "#parks_df.to_sql(\"parks\", engine, if_exists=\"replace\", index=False)\n",
    "transport_requests.to_sql(\"transport_requests\", engine, if_exists=\"replace\", index=False)\n",
    "waste_requests.to_sql(\"waste_requests\",engine, if_exists=\"replace\", index=False)\n",
    "municipal_requests.to_sql(\"municipal_requests\",engine, if_exists=\"replace\", index=False)\n",
    "water_requests.to_sql(\"water_requests\",engine, if_exists=\"replace\", index=False)\n",
    "#collisions_cleaned.to_sql('collisions',engine, if_exists='replace', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "be9347a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "service_request_type\n",
       "Road Pot Hole / Road Damage                                      156177\n",
       "Missing / Damaged Street Or Traffic Signs                         60204\n",
       "Damaged Concrete Sidewalk                                         37020\n",
       "Road Sinking                                                      26643\n",
       "Boulevards Damaged Asphalt                                        22763\n",
       "Boulevard Plow Damage                                             19943\n",
       "Maintenance Holes Damage / Repair                                  9779\n",
       "Driveway Damaged / Ponding                                         8491\n",
       "Curb Damaged                                                       7890\n",
       "Missing/Faded Pavement Markings                                    6281\n",
       "Laneway Surface Damage                                             6061\n",
       "Damaged Catch Basin On The Roadside                                5681\n",
       "Walkway Damaged Or Uneven                                          5484\n",
       "Sidewalk Damaged /Brick/Interlock                                  4269\n",
       "Catch Basin Damaged Maintenance Request                            3442\n",
       "Roadside Plow Damage                                               2511\n",
       "Investigate Pavement Markings                                      2441\n",
       "Bollard Damaged                                                    2224\n",
       "Culverts Damaged / Maintenance Request                             1965\n",
       "Fence Damaged                                                      1802\n",
       "Catch Basin Cover Missing / Damaged / Loose                        1655\n",
       "Missing/Damaged Flexible Bollards                                  1293\n",
       "Guardrail Damaged                                                  1278\n",
       "Retaining Wall Damage / Repair                                     1238\n",
       "Automated Speed Enforcement (Ase ) Camera Vandalism Or Damage       582\n",
       "Damaged Bike Lane Barrier                                           281\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish keywords for road damage related service requests\n",
    "\n",
    "words = ['Damage','Pavement','Sinking','Asphalt','Laneway - Surface Damage','Road damaged on Expressway','Curb - Damaged','Road - Damaged','Bridge - Damaged Structure',\n",
    "'Shoulder on Expressway Damaged','Sidewalk - Damaged / Concrete','Sidewalk - Damaged /Brick/Interlock','Traffic Island - Damaged','Walkway - Damaged']\n",
    "pattern = '|'.join(words)\n",
    "\n",
    "transport_requests[transport_requests['service_request_type'].str.contains(pattern, case=False, na=False)]['service_request_type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d3042b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "section              \n",
       "Road Operations          326316\n",
       "TMC                       67778\n",
       "Traffic Ops                2441\n",
       "Permits & Enforcement       582\n",
       "Traffic Management          281\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transport_requests[transport_requests['service_request_type'].str.contains(pattern, case=False, na=False)][['section']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "614626d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "section           \n",
       "Road Operations       120604\n",
       "Right of Way (ROW)     25628\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store keywords related to winter maintenance requests\n",
    "winter_words = ['Salting','Snow','Icy','Plough','Winter']\n",
    "winter_pattern = '|'.join(winter_words)\n",
    "\n",
    "transport_requests[transport_requests['service_request_type'].str.contains(winter_pattern, case=False, na=False)][['section']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f5236431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_address                                        \n",
       "M6E  Toronto Ontario                                    3002\n",
       "M6H  Toronto Ontario                                    2577\n",
       "M6G  Toronto Ontario                                    2439\n",
       "M6P  Toronto Ontario                                    2416\n",
       "M1B  Toronto Ontario                                    2210\n",
       "                                                        ... \n",
       " East York Ave Mortimer Ave Toronto Ontario                1\n",
       " Eastern Ave Diversion Adelaide St E Toronto Ontario       1\n",
       " Eastern Ave Diversion Richmond St E Toronto Ontario       1\n",
       " 110 Ling Rd 120 Ling Rd Toronto Ontario                   1\n",
       "M5X  Toronto Ontario                                       1\n",
       "Name: count, Length: 10497, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transport_requests[transport_requests['service_request_type'].str.contains(winter_pattern, case=False, na=False)][['full_address']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8007bb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "service_request_type\n",
       "Illegal Off Street Parking         8497\n",
       "Illegal On Street Parking          2636\n",
       "Disabled Persons' Parking Space    2256\n",
       "General Parking Regulations        2128\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parking_words = ['Parking']\n",
    "transport_requests[transport_requests['service_request_type'].str.contains('Parking', case=False, na=False)]['service_request_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0c7c4306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "service_request_type\n",
       "Missing / Damaged Street Or Traffic Signs         60204\n",
       "Traffic Signal Repair                             51579\n",
       "Vehicle Traffic Signal Issue                       5377\n",
       "Traffic Signal Equipment Graffiti Complaint        4454\n",
       "Traffic Calming Measures                           4108\n",
       "Left/Right Turn Signal Priority Features           3270\n",
       "Pedestrian Signal Issue                            2533\n",
       "Traffic Island Grass Needs Cutting                 2231\n",
       "Traffic Or Street Name Sign Graffiti Complaint     2188\n",
       "New Traffic Control Signal Request                 2006\n",
       "Traffic Signal Information Requests                  53\n",
       "Bus/Streetcar Signal Issues                          21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_signal_words = ['Traffic Signal','Traffic light','Signal','Traffic']\n",
    "traffic_pattern = '|'.join(traffic_signal_words)\n",
    "transport_requests[transport_requests['service_request_type'].str.contains(traffic_pattern, case=False, na=False)]['service_request_type'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
